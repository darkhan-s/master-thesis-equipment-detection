\babel@toc {english}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Machine learning concepts \cite {Janiesch2021}.\relax }}{16}{figure.caption.11}%
\contentsline {figure}{\numberline {2}{\ignorespaces A biological(a) neuron against artificial(b) and biological synapse(c) against artificial(d) \cite {article1}.\relax }}{17}{figure.caption.12}%
\contentsline {figure}{\numberline {3}{\ignorespaces Backpropogation algorithm, adapted from \cite {Alber2018}.\relax }}{18}{figure.caption.13}%
\contentsline {figure}{\numberline {4}{\ignorespaces A simple CNN network with 5 layers for image classification task \cite {Mahony2019}.\relax }}{20}{figure.caption.14}%
\contentsline {figure}{\numberline {5}{\ignorespaces The process of convolution \cite {Liu2016}.\relax }}{20}{figure.caption.15}%
\contentsline {figure}{\numberline {6}{\ignorespaces Evolution of image classifier models evaluated on ImageNet dataset \cite {alom01}.\relax }}{21}{figure.caption.16}%
\contentsline {figure}{\numberline {7}{\ignorespaces LeNet architecture \cite {alom01}.\relax }}{22}{figure.caption.17}%
\contentsline {figure}{\numberline {8}{\ignorespaces AlexNet architecture \cite {alom01}.\relax }}{23}{figure.caption.18}%
\contentsline {figure}{\numberline {9}{\ignorespaces VGG architecture \cite {alom01}.\relax }}{23}{figure.caption.19}%
\contentsline {figure}{\numberline {10}{\ignorespaces Residual block of ResNet \cite {He2015}.\relax }}{24}{figure.caption.20}%
\contentsline {figure}{\numberline {11}{\ignorespaces ResNet architecture \cite {resnet50}.\relax }}{24}{figure.caption.21}%
\contentsline {figure}{\numberline {12}{\ignorespaces Types of object detectors.\relax }}{25}{figure.caption.22}%
\contentsline {figure}{\numberline {13}{\ignorespaces A simple single-stage detector(left) compared to a two-stage detector(right) \cite {app8091488}.\relax }}{26}{figure.caption.23}%
\contentsline {figure}{\numberline {14}{\ignorespaces R-CNN overview \cite {Girshick2013}.\relax }}{26}{figure.caption.24}%
\contentsline {figure}{\numberline {15}{\ignorespaces Fast-RCNN overview \cite {Girshick2015}.\relax }}{27}{figure.caption.25}%
\contentsline {figure}{\numberline {16}{\ignorespaces Faster-RCNN overview and its RPN module \cite {ima}.\relax }}{28}{figure.caption.26}%
\contentsline {figure}{\numberline {17}{\ignorespaces The popularity of different detectors according to \cite {paperswithcode_1:2022}.\relax }}{29}{figure.caption.27}%
\contentsline {figure}{\numberline {18}{\ignorespaces YOLO overview \cite {Redmon2015a}.\relax }}{30}{figure.caption.28}%
\contentsline {figure}{\numberline {19}{\ignorespaces SSD compared to YOLO \cite {Liu2015}.\relax }}{31}{figure.caption.29}%
\contentsline {figure}{\numberline {20}{\ignorespaces SSD anchor boxes \cite {Liu2015}.\relax }}{31}{figure.caption.30}%
\contentsline {figure}{\numberline {21}{\ignorespaces Comparison of ML to TL \cite {Pan2010}.\relax }}{34}{figure.caption.32}%
\contentsline {figure}{\numberline {22}{\ignorespaces Distribution alignment types \cite {Zhang2021}.\relax }}{35}{figure.caption.33}%
\contentsline {figure}{\numberline {23}{\ignorespaces Unsupervised Domain Adaptive Object Detection.\relax }}{36}{figure.caption.34}%
\contentsline {figure}{\numberline {24}{\ignorespaces Domain-adversarial neural network and GRL \cite {Ganin2015}.\relax }}{37}{figure.caption.35}%
\contentsline {figure}{\numberline {25}{\ignorespaces Domain Adaptive Faster R-CNN for Object Detection in the Wild \cite {Chen2018}.\relax }}{38}{figure.caption.36}%
\contentsline {figure}{\numberline {26}{\ignorespaces Seeking Similarities over Differences: Similarity-based Domain Alignment for Adaptive Object Detection, adapted from \cite {Rezaeianaran2021}.\relax }}{39}{figure.caption.37}%
\contentsline {figure}{\numberline {27}{\ignorespaces A Robust Learning Approach to Domain Adaptive Object Detection \cite {Khodabandeh2019}.\relax }}{40}{figure.caption.38}%
\contentsline {figure}{\numberline {28}{\ignorespaces Progressive Domain Adaptation for Object Detection and CycleGAN, adapted from \cite {Hsu2019}.\relax }}{41}{figure.caption.39}%
\contentsline {figure}{\numberline {29}{\ignorespaces Diversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection, adapted from \cite {Kim2019}.\relax }}{42}{figure.caption.40}%
\contentsline {figure}{\numberline {30}{\ignorespaces Exploring Object Relation in Mean Teacher for Cross-Domain Detection \cite {Cai2019}.\relax }}{43}{figure.caption.41}%
\contentsline {figure}{\numberline {31}{\ignorespaces Unbiased Teacher for Semi-Supervised Object Detection \cite {Liu2021}.\relax }}{44}{figure.caption.42}%
\contentsline {figure}{\numberline {32}{\ignorespaces Cross-Domain Adaptive Teacher for Object Detection \cite {Li2021}.\relax }}{45}{figure.caption.43}%
\contentsline {figure}{\numberline {33}{\ignorespaces Augmentations used in Unbiased Teacher (adapted from the official Pytorch documentation \cite {pytorch}).\relax }}{46}{figure.caption.44}%
\contentsline {figure}{\numberline {34}{\ignorespaces Continual learning approaches \cite {Parisi2018}.\relax }}{47}{figure.caption.45}%
\contentsline {figure}{\numberline {35}{\ignorespaces Example of the rendered image of an arbitrary model.\relax }}{49}{figure.caption.46}%
\contentsline {figure}{\numberline {36}{\ignorespaces T-LESS real setup, labeled \cite {hodan2017tless}.\relax }}{50}{figure.caption.47}%
\contentsline {figure}{\numberline {37}{\ignorespaces Distribution of the classes in the rendered subset of T-LESS dataset. Total number of images: 42 500. Total number of object instances: 661598.\relax }}{51}{figure.caption.48}%
\contentsline {figure}{\numberline {38}{\ignorespaces Distribution of the classes in the real subset of T-LESS dataset. 8 568 and 1 512 (85/15 \%) training and testing images, respectively. Total number of object instances: 58845 training and 10362 validation instances.\relax }}{52}{figure.caption.49}%
\contentsline {figure}{\numberline {39}{\ignorespaces Visual representation of the terms used in the PASCAL VOC metrics.\relax }}{54}{figure.caption.51}%
\contentsline {figure}{\numberline {40}{\ignorespaces Smoothed average precision curve \cite {mAp_blog}.\relax }}{55}{figure.caption.52}%
\contentsline {figure}{\numberline {41}{\ignorespaces Results of the experiments with Adaptive Teacher as it is.\relax }}{58}{figure.caption.56}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Visualization on the source dataset}}}{58}{subfigure.41.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Visualization on the target dataset}}}{58}{subfigure.41.2}%
\contentsline {figure}{\numberline {42}{\ignorespaces a) The original LR scheduler against b) The proposed cosine annealing LR scheduler without restarts.\relax }}{59}{figure.caption.57}%
\contentsline {figure}{\numberline {43}{\ignorespaces A proposed architecture for cross-domain object detection. Blue elements represent standard Faster-RCNN components, purple elements - domain adaptation components and yellow elements are Faster-RCNN modified components for continual learning, which will be discussed later.\relax }}{60}{figure.caption.58}%
\contentsline {figure}{\numberline {44}{\ignorespaces Augmentations used in the experiments.\relax }}{62}{figure.caption.59}%
\contentsline {figure}{\numberline {45}{\ignorespaces A proposed architecture for continual learning setup. Blue elements represent standard Faster-RCNN components, yellow elements are modified components for continual learning.\relax }}{66}{figure.caption.61}%
\contentsline {figure}{\numberline {46}{\ignorespaces Results of the original Adaptive Teacher model evaluated on the custom T-LESS dataset without any modifications.\relax }}{68}{figure.caption.62}%
\contentsline {figure}{\numberline {47}{\ignorespaces a) \texttt {AP50} results of the original model and b) \texttt {AP50} results of the model with a cosine scheduler.\relax }}{69}{figure.caption.63}%
\contentsline {figure}{\numberline {48}{\ignorespaces a) \texttt {AP50} of the model with a cosine scheduler only and b) \texttt {AP50} results of the model with a cosine scheduler, two additional strong augmentations and the early-stopping algorithm.\relax }}{70}{figure.caption.64}%
\contentsline {figure}{\numberline {49}{\ignorespaces a) \texttt {AP50} of the model with a cosine scheduler and two extra augmentations against b) \texttt {AP50} of the model with a cosine scheduler, two additional augmentations and a consistency regularization.\relax }}{71}{figure.caption.65}%
\contentsline {figure}{\numberline {50}{\ignorespaces a) The total loss calculation is independent from consistency loss and the instance-level loss terms b) The total loss is proportional to the consistency loss and the instance-level loss terms.\relax }}{72}{figure.caption.66}%
\contentsline {figure}{\numberline {51}{\ignorespaces \texttt {AP50} values for varying weight parameters of $\lambda _{\text {consist }}$, $\lambda _{\text {ins }}$ and \texttt {BASE\textunderscore LR}.\relax }}{72}{figure.caption.67}%
\contentsline {figure}{\numberline {52}{\ignorespaces a) Original model without any modifications b) The custom model with the cosine scheduler c) The custom model with the original scheduler.\relax }}{73}{figure.caption.68}%
\contentsline {figure}{\numberline {53}{\ignorespaces a) Average values of \texttt {AP50} for the classes 1 to 4 b) Average values of \texttt {AP50} for the classes 5 to 30 extracted from the same model results. \relax }}{74}{figure.caption.69}%
\contentsline {figure}{\numberline {54}{\ignorespaces The \texttt {AP50} results for class \texttt {Model 21} evaluated in three different setups.\relax }}{75}{figure.caption.70}%
\contentsline {figure}{\numberline {55}{\ignorespaces a) The total \texttt {AP50} value evaluated on the classes \texttt {Model 1..Model 21} using continual learning b) The total \texttt {AP50} results for the classes \texttt {Model 1..Model 30} on the model that was trained from scratch.\relax }}{76}{figure.caption.71}%
\contentsline {figure}{\numberline {56}{\ignorespaces a) The average \texttt {AP50} value for continual learning on classes \texttt {Model 21..Model 30} given the model trained on classes \texttt {Model 1..Model 20} b) The average \texttt {AP50} value for classes \texttt {Model 21..Model 30} extracted from the original model trained from scratch on classes \texttt {Model 1..Model 30} c) The \texttt {AP50} value for each of the classes \texttt {Model 21..Model 30} when trained individually. The values are then averaged out for all 10 classes.\relax }}{77}{figure.caption.72}%
\contentsline {figure}{\numberline {57}{\ignorespaces A screenshot of the simple web app. The image on the left-hand side represents an uploaded target image with the objects to predict, and the image on the right-hand side returns the localized objects.\relax }}{78}{figure.caption.73}%
\contentsline {figure}{\numberline {58}{\ignorespaces Labeled image of the rendered \texttt {HM-75S} pump\relax }}{79}{figure.caption.74}%
\contentsline {figure}{\numberline {59}{\ignorespaces Unlabeled image of the real \texttt {HM-75S} pump\relax }}{79}{figure.caption.74}%
\contentsline {figure}{\numberline {60}{\ignorespaces The performance of the proposed model on the custom dataset with one industrial object.\relax }}{80}{figure.caption.75}%
\contentsline {figure}{\numberline {61}{\ignorespaces The demonstration of the model performance. The model was trained on the source and target images of the \texttt {HM-75S} pump.\relax }}{81}{figure.caption.76}%
