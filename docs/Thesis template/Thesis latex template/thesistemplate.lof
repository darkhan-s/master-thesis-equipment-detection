\babel@toc {english}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Machine learning concepts \cite {Janiesch2021}.\relax }}{17}{figure.caption.13}%
\contentsline {figure}{\numberline {2}{\ignorespaces A biological(a) neuron against artificial(b) and biological synapse(c) against artificial(d) \cite {article1}.\relax }}{18}{figure.caption.14}%
\contentsline {figure}{\numberline {3}{\ignorespaces Backpropogation algorithm, adapted from \cite {Alber2018}.\relax }}{19}{figure.caption.15}%
\contentsline {figure}{\numberline {4}{\ignorespaces A simple CNN network with 5 layers for image classification task \cite {Mahony2019}.\relax }}{21}{figure.caption.16}%
\contentsline {figure}{\numberline {5}{\ignorespaces The process of convolution \cite {Liu2016}.\relax }}{21}{figure.caption.17}%
\contentsline {figure}{\numberline {6}{\ignorespaces Evolution of image classifier models evaluated on ImageNet dataset \cite {alom01}.\relax }}{22}{figure.caption.18}%
\contentsline {figure}{\numberline {7}{\ignorespaces LeNet architecture \cite {alom01}.\relax }}{23}{figure.caption.19}%
\contentsline {figure}{\numberline {8}{\ignorespaces AlexNet architecture \cite {alom01}.\relax }}{24}{figure.caption.20}%
\contentsline {figure}{\numberline {9}{\ignorespaces VGG architecture \cite {alom01}.\relax }}{24}{figure.caption.21}%
\contentsline {figure}{\numberline {10}{\ignorespaces Residual block of ResNet \cite {He2015}.\relax }}{25}{figure.caption.22}%
\contentsline {figure}{\numberline {11}{\ignorespaces ResNet architecture \cite {resnet50}.\relax }}{25}{figure.caption.23}%
\contentsline {figure}{\numberline {12}{\ignorespaces Types of object detectors.\relax }}{26}{figure.caption.24}%
\contentsline {figure}{\numberline {13}{\ignorespaces A simple single-stage detector(left) compared to a two-stage detector(right) \cite {app8091488}.\relax }}{27}{figure.caption.25}%
\contentsline {figure}{\numberline {14}{\ignorespaces R-CNN overview \cite {Girshick2013}.\relax }}{28}{figure.caption.26}%
\contentsline {figure}{\numberline {15}{\ignorespaces Fast-RCNN overview \cite {Girshick2015}.\relax }}{28}{figure.caption.27}%
\contentsline {figure}{\numberline {16}{\ignorespaces Faster-RCNN overview and its RPN module \cite {ima}.\relax }}{29}{figure.caption.28}%
\contentsline {figure}{\numberline {17}{\ignorespaces The popularity of different detectors according to \cite {paperswithcode_1:2022}.\relax }}{30}{figure.caption.29}%
\contentsline {figure}{\numberline {18}{\ignorespaces YOLO overview \cite {Redmon2015a}.\relax }}{31}{figure.caption.30}%
\contentsline {figure}{\numberline {19}{\ignorespaces SSD compared to YOLO \cite {Liu2015}.\relax }}{32}{figure.caption.31}%
\contentsline {figure}{\numberline {20}{\ignorespaces SSD anchor boxes \cite {Liu2015}.\relax }}{32}{figure.caption.32}%
\contentsline {figure}{\numberline {21}{\ignorespaces Comparison of ML to TL \cite {Pan2010}.\relax }}{35}{figure.caption.36}%
\contentsline {figure}{\numberline {22}{\ignorespaces Distribution alignment types \cite {Zhang2021}.\relax }}{36}{figure.caption.37}%
\contentsline {figure}{\numberline {23}{\ignorespaces Unsupervised Domain Adaptive Object Detection.\relax }}{37}{figure.caption.38}%
\contentsline {figure}{\numberline {24}{\ignorespaces Domain-adversarial neural network and GRL \cite {Ganin2015}.\relax }}{38}{figure.caption.39}%
\contentsline {figure}{\numberline {25}{\ignorespaces Domain Adaptive Faster R-CNN for Object Detection in the Wild \cite {Chen2018}.\relax }}{39}{figure.caption.41}%
\contentsline {figure}{\numberline {26}{\ignorespaces Seeking Similarities over Differences: Similarity-based Domain Alignment for Adaptive Object Detection, adapted from \cite {Rezaeianaran2021}.\relax }}{41}{figure.caption.43}%
\contentsline {figure}{\numberline {27}{\ignorespaces A Robust Learning Approach to Domain Adaptive Object Detection \cite {Khodabandeh2019}.\relax }}{42}{figure.caption.44}%
\contentsline {figure}{\numberline {28}{\ignorespaces Progressive Domain Adaptation for Object Detection and CycleGAN, adapted from \cite {Hsu2019}.\relax }}{43}{figure.caption.45}%
\contentsline {figure}{\numberline {29}{\ignorespaces Diversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection, adapted from \cite {Kim2019}.\relax }}{44}{figure.caption.46}%
\contentsline {figure}{\numberline {30}{\ignorespaces Exploring Object Relation in Mean Teacher for Cross-Domain Detection \cite {Cai2019}.\relax }}{45}{figure.caption.47}%
\contentsline {figure}{\numberline {31}{\ignorespaces Unbiased Teacher for Semi-Supervised Object Detection \cite {Liu2021}.\relax }}{46}{figure.caption.48}%
\contentsline {figure}{\numberline {32}{\ignorespaces Cross-Domain Adaptive Teacher for Object Detection \cite {Li2021}.\relax }}{47}{figure.caption.49}%
\contentsline {figure}{\numberline {33}{\ignorespaces Augmentations used in Unbiased teacher (adapted from the official Pytorch documentation \cite {pytorch}).\relax }}{48}{figure.caption.50}%
\contentsline {figure}{\numberline {34}{\ignorespaces Continual learning approaches \cite {Parisi2018}.\relax }}{49}{figure.caption.51}%
\contentsline {figure}{\numberline {35}{\ignorespaces Example of the rendered image of an arbitrary model.\relax }}{50}{figure.caption.54}%
\contentsline {figure}{\numberline {36}{\ignorespaces T-LESS real setup, labeled \cite {hodan2017tless}.\relax }}{51}{figure.caption.55}%
\contentsline {figure}{\numberline {37}{\ignorespaces Distribution of the classes in the rendered subset of T-LESS dataset. Total number of images: 42 500. Total number of object instances: 661598.\relax }}{52}{figure.caption.56}%
\contentsline {figure}{\numberline {38}{\ignorespaces Distribution of the classes in the real subset of T-LESS dataset. 8 568 and 1 512 (85/15 \%) training and testing images, respectively. Total number of object instances: 58845 training and 10362 validation instances.\relax }}{53}{figure.caption.57}%
\contentsline {figure}{\numberline {39}{\ignorespaces Average precision curve \cite {mAp_blog}.\relax }}{55}{figure.caption.61}%
\contentsline {figure}{\numberline {40}{\ignorespaces Results of the experiments with Adaptive Teacher as it is.\relax }}{58}{figure.caption.65}%
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Visualization on the source dataset}}}{58}{subfigure.40.1}%
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Visualization on the target dataset}}}{58}{subfigure.40.2}%
\contentsline {figure}{\numberline {41}{\ignorespaces a) The original LR scheduler against b) The proposed cosine annealing LR scheduler without restarts.\relax }}{60}{figure.caption.67}%
\contentsline {figure}{\numberline {42}{\ignorespaces A proposed architecture for cross-domain object detection. Blue elements represent standard Faster-RCNN components, purple elements - domain adaptation components and yellow elements are Faster-RCNN modified components for continual learning, which will be discussed later.\relax }}{61}{figure.caption.68}%
\contentsline {figure}{\numberline {43}{\ignorespaces Augmentations used in the experiments.\relax }}{62}{figure.caption.69}%
\contentsline {figure}{\numberline {44}{\ignorespaces A proposed architecture for continual learning setup. Blue elements represent standard Faster-RCNN components, yellow elements are modified components for continual learning.\relax }}{66}{figure.caption.71}%
\contentsline {figure}{\numberline {45}{\ignorespaces Results of the original Adaptive teacher model evaluated on the custom T-LESS dataset without any modifications.\relax }}{68}{figure.caption.72}%
\contentsline {figure}{\numberline {46}{\ignorespaces a)\texttt {AP50} results of the original model and b) \texttt {AP50} results of the model with a cosine scheduler.\relax }}{69}{figure.caption.73}%
\contentsline {figure}{\numberline {47}{\ignorespaces a)\texttt {AP50} from the model with a modified scheduler only and b) \texttt {AP50} results of the model with a cosine scheduler and two additional strong augmentations.\relax }}{70}{figure.caption.74}%
\contentsline {figure}{\numberline {48}{\ignorespaces a)\texttt {AP50} from the model with a cosine scheduler and two extra augmentations against b) \texttt {AP50} from the model with a cosine scheduler, two additional augmentations and consistency regularization.\relax }}{71}{figure.caption.75}%
\contentsline {figure}{\numberline {49}{\ignorespaces a) The total loss calculation is independent from consistency loss and the instance-level loss terms b) The total loss is proportional to the consistency loss and the instance-level loss terms.\relax }}{72}{figure.caption.76}%
\contentsline {figure}{\numberline {50}{\ignorespaces \texttt {AP50} values for varying weight parameters of $\lambda _{\text {consist }}$, $\lambda _{\text {ins }}$ and \texttt {BASE\textunderscore LR}.\relax }}{73}{figure.caption.77}%
\contentsline {figure}{\numberline {51}{\ignorespaces a) The custom model with the original scheduler b) The custom model with the cosine scheduler c) Original model without any modifications.\relax }}{74}{figure.caption.78}%
\contentsline {figure}{\numberline {52}{\ignorespaces a)\texttt {AP50}.\relax }}{75}{figure.caption.79}%
\contentsline {figure}{\numberline {53}{\ignorespaces The \texttt {AP50} results for class \texttt {Model 21} evaluated on different networks.\relax }}{76}{figure.caption.80}%
\contentsline {figure}{\numberline {54}{\ignorespaces a)The total continual \texttt {AP50} results evaluated on the classes (\texttt {Model 1..Model 21}) b) The total \texttt {AP50} results for the .\relax }}{77}{figure.caption.82}%
\contentsline {figure}{\numberline {55}{\ignorespaces a)The average \texttt {AP50} value for continual learning on classes \texttt {Model 21..Model 25} given the model trained on classes \texttt {Model 1..Model 20} b)The average \texttt {AP50} value for classes \texttt {Model 21..Model 25} extracted from the regular model trained on classes \texttt {Model 1..Model 30} c) The \texttt {AP50} value for each of the classes \texttt {Model 21..Model 25} when trained only on its own. The values are then averaged out for all 5 classes.\relax }}{78}{figure.caption.83}%
\contentsline {figure}{\numberline {56}{\ignorespaces A screenshot of the simple web app. The image on the left-hand side is an uploaded target image, and the image on the right-hand side shows a prediction of the objects.\relax }}{79}{figure.caption.84}%
